{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "eb5ddf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9264a011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a8ee731e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        The reception through this headset is excellent.\n",
      "1              Hands down my favorite Italian restaurant!\n",
      "2       The bathrooms are clean and the place itself i...\n",
      "3                        If you haven't gone here GO NOW!\n",
      "4       Host staff were, for lack of a better word, BI...\n",
      "                              ...                        \n",
      "1924                                        It just blew.\n",
      "1925    A few pounds thinner than I am now, I didn't g...\n",
      "1926           How can that be?The audio quality is poor.\n",
      "1927    We spent the money and we quadrupled the debt,...\n",
      "1928    To sum the film up, \"Breeders\" is a terrible, ...\n",
      "Name: text, Length: 1929, dtype: object\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('PS1.1A_test_data.txt', sep=\"\\t\", names=[\"serial\",\"text\",\"sentiment\",\"a\",\"b\"])\n",
    "print(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0fea74a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEGATIVE    949\n",
      "POSITIVE    917\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "test = test[test.sentiment != \"NEUTRAL\"]\n",
    "X_test = test['text'].str.lower()\n",
    "y_test = test['sentiment']\n",
    "print(test['sentiment'].value_counts())\n",
    "# print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83f90830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEGATIVE    1282\n",
      "POSITIVE    1074\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('PS1.1A_training_data.txt', sep=\"\\t\", names=[\"serial\",\"text\",\"sentiment\",\"a\",\"b\"])\n",
    "train = train[train.sentiment != \"NEUTRAL\"]\n",
    "X_train = train['text'].str.lower()\n",
    "y_train = train['sentiment']\n",
    "print(train['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "caa5137b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5596)\t1\n",
      "  (0, 2971)\t1\n",
      "  (0, 1546)\t1\n",
      "  (0, 3694)\t1\n",
      "  (0, 2614)\t1\n",
      "  (0, 2802)\t1\n",
      "  (0, 6303)\t1\n",
      "  (0, 5260)\t1\n",
      "  (0, 1744)\t1\n",
      "  (0, 3798)\t1\n",
      "  (0, 270)\t1\n",
      "  (0, 999)\t1\n",
      "  (0, 4109)\t1\n",
      "  (0, 5928)\t1\n",
      "  (0, 6151)\t1\n",
      "  (0, 1810)\t1\n",
      "  (1, 2983)\t2\n",
      "  (1, 2483)\t1\n",
      "  (1, 4150)\t1\n",
      "  (1, 314)\t1\n",
      "  (1, 2684)\t1\n",
      "  (1, 4487)\t1\n",
      "  (2, 4109)\t1\n",
      "  (2, 314)\t2\n",
      "  (2, 918)\t1\n",
      "  :\t:\n",
      "  (2354, 5568)\t1\n",
      "  (2354, 213)\t1\n",
      "  (2354, 5567)\t1\n",
      "  (2354, 2548)\t2\n",
      "  (2354, 5662)\t1\n",
      "  (2354, 2764)\t1\n",
      "  (2354, 2174)\t1\n",
      "  (2354, 3950)\t2\n",
      "  (2354, 282)\t1\n",
      "  (2354, 3698)\t1\n",
      "  (2354, 3885)\t1\n",
      "  (2354, 216)\t1\n",
      "  (2354, 6085)\t2\n",
      "  (2354, 3558)\t1\n",
      "  (2354, 2281)\t1\n",
      "  (2354, 2180)\t1\n",
      "  (2354, 1151)\t1\n",
      "  (2354, 4457)\t1\n",
      "  (2354, 804)\t1\n",
      "  (2354, 1584)\t1\n",
      "  (2355, 3878)\t1\n",
      "  (2355, 3674)\t1\n",
      "  (2355, 4279)\t1\n",
      "  (2355, 2207)\t1\n",
      "  (2355, 2853)\t1\n"
     ]
    }
   ],
   "source": [
    "# text_unigram = [ngrams(sent, 1) for sent in X_train]\n",
    "CountVec = CountVectorizer(ngram_range=(1,1)) #,stop_words='english'\n",
    "x_test_1 = CountVec.fit_transform(X_test)\n",
    "Count_data = CountVec.fit_transform(X_train)\n",
    "print(Count_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "518baedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop = stopwords.words('english')\n",
    "# X_train_wos = X_train.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "# print(X_train_wos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b00fd2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1866, 4639)\n",
      "(2356, 6324)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-a18bdf1efc1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCount_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# y_pred = clf.predict(x_test_1.toarray())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "# print(Count_data)\n",
    "# print(y_train)\n",
    "# CountVec = CountVectorizer(ngram_range=(1,1),stop_words='english')\n",
    "print(x_test_1.shape)\n",
    "print(Count_data.shape)\n",
    "clf = gnb.fit(Count_data.toarray(), y_train)\n",
    "# y_pred = clf.predict(x_test_1.toarray())\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b988f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2267cb67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
