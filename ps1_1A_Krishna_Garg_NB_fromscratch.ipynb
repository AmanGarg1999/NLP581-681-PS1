{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint\n",
    "from nltk.corpus import stopwords\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>This is definitely a must have if your state d...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>GENRE_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's a great place and I highly recommend it.</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>GENRE_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I will see the doctors, take some blood tests ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>GOING_TO_PLACES</td>\n",
       "      <td>GENRE_A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I can tell you about having my phone and elect...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>MONEY_ISSUE</td>\n",
       "      <td>GENRE_A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Their steaks are 100% recommended!</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>GENRE_B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               TEXT Sentiment  \\\n",
       "0   0  This is definitely a must have if your state d...  POSITIVE   \n",
       "1   1      It's a great place and I highly recommend it.  POSITIVE   \n",
       "2   2  I will see the doctors, take some blood tests ...   NEUTRAL   \n",
       "3   3  I can tell you about having my phone and elect...  NEGATIVE   \n",
       "4   4                 Their steaks are 100% recommended!  POSITIVE   \n",
       "\n",
       "             Topic    Genre  \n",
       "0             NONE  GENRE_B  \n",
       "1             NONE  GENRE_B  \n",
       "2  GOING_TO_PLACES  GENRE_A  \n",
       "3      MONEY_ISSUE  GENRE_A  \n",
       "4             NONE  GENRE_B  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('PS1.1A_training_data.txt',sep=\"\\t\", names=[\"ID\",\"TEXT\",\"Sentiment\",\"Topic\",\"Genre\"])\n",
    "data.head(5)\n",
    "# data = pd.read_csv('train.csv')\n",
    "# data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_TEXT(dataframe):\n",
    "    dataframe['TEXT'] = dataframe.TEXT.fillna('none')\n",
    "    #dataframe['Sentiment'] = dataframe.Sentiment.fillna('none')\n",
    "    #dataframe['Topic'] = dataframe.Topic.fillna('none')\n",
    "    dataframe['Genre'] = dataframe.Genre.fillna('none')\n",
    "    dataframe = dataframe[dataframe.Sentiment != 'NEUTRAL']\n",
    "    dataframe['TEXT'] = dataframe['TEXT'].str.lower()\n",
    "    STOPWORDS = []\n",
    "    STOPWORDS = stopwords\n",
    "    \n",
    "    columns = list(dataframe.columns)\n",
    "    \n",
    "    for column in columns:\n",
    "        if column != 'ID':\n",
    "            dataframe[column] = dataframe[column].str.replace(r'\\W', ' ').str.replace(r'\\s$','')\n",
    "            \n",
    "    \n",
    "    for column in columns:\n",
    "        dataframe = remove_stop_words(dataframe,column)\n",
    "    \n",
    "    for column in columns:\n",
    "        dataframe = remove_special_characters(dataframe,column)\n",
    "    \n",
    "    #dataframe['Text_Genre'] = dataframe['TEXT'] + dataframe['Genre']\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "        \n",
    "def remove_stop_words(data_frame, column_name):\n",
    "    if column_name != 'ID':\n",
    "        data_frame[column_name] = data_frame[column_name].apply(lambda x: \" \".join([i for i in x.lower().split() if i not in STOPWORDS]))\n",
    "    return data_frame\n",
    "\n",
    "def remove_special_characters(data_frame, columns):\n",
    "    data_frame.columns = data_frame.columns.str.replace('[!,@,#,$,%,^,&,*,\\\",:,;,.]','')\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = clean_TEXT(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>definitely state allow cell phone usage driving</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>genre_b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>s great place highly recommend</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>genre_b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tell having phone electricity gas cut couldn t...</td>\n",
       "      <td>negative</td>\n",
       "      <td>money_issue</td>\n",
       "      <td>genre_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>steaks 100 recommended</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>genre_b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>billed thousands dollars said feeling shock un...</td>\n",
       "      <td>negative</td>\n",
       "      <td>money_issue</td>\n",
       "      <td>genre_a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               TEXT Sentiment  \\\n",
       "0   0    definitely state allow cell phone usage driving  positive   \n",
       "1   1                     s great place highly recommend  positive   \n",
       "3   3  tell having phone electricity gas cut couldn t...  negative   \n",
       "4   4                             steaks 100 recommended  positive   \n",
       "5   5  billed thousands dollars said feeling shock un...  negative   \n",
       "\n",
       "         Topic    Genre  \n",
       "0               genre_b  \n",
       "1               genre_b  \n",
       "3  money_issue  genre_a  \n",
       "4               genre_b  \n",
       "5  money_issue  genre_a  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['TEXT'], data['Sentiment'],test_size=0.25,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1765,)\n",
      "(1765,)\n",
      "(589,)\n",
      "(589,)\n",
      "<bound method Series.unique of 581     negative\n",
      "246     negative\n",
      "1844    positive\n",
      "13      negative\n",
      "593     positive\n",
      "          ...   \n",
      "1121    positive\n",
      "2309    positive\n",
      "1543    positive\n",
      "1869    negative\n",
      "2451    negative\n",
      "Name: Sentiment, Length: 1765, dtype: object>\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape), print(y_train.shape)\n",
    "print(X_test.shape), print(y_test.shape)\n",
    "#print(X_train.head(5))\n",
    "print(y_train.unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier(object):\n",
    "    def __init__(self, n_gram=1, printing=False):\n",
    "        self.prior = defaultdict(int)\n",
    "        self.logprior = {}\n",
    "        self.bigdoc = defaultdict(list)\n",
    "        self.loglikelihoods = defaultdict(defaultdict)\n",
    "        self.V = []\n",
    "        self.n = n_gram\n",
    "\n",
    "    def compute_prior_and_bigdoc(self, training_set, training_labels):\n",
    "        for x, y in zip(training_set, training_labels):\n",
    "            all_words = x.split(\" \")\n",
    "            if self.n == 1:\n",
    "                grams = all_words\n",
    "            else:\n",
    "                grams = self.words_to_grams(all_words)\n",
    "\n",
    "            self.prior[y] += len(grams)\n",
    "            self.bigdoc[y].append(x)\n",
    "\n",
    "    def compute_vocabulary(self, documents):\n",
    "        vocabulary = set()\n",
    "\n",
    "        for doc in documents:\n",
    "            for word in doc.split(\" \"):\n",
    "                vocabulary.add(word.lower())\n",
    "\n",
    "        return vocabulary\n",
    "\n",
    "    def count_word_in_classes(self):\n",
    "        counts = {}\n",
    "        for c in list(self.bigdoc.keys()):\n",
    "            docs = self.bigdoc[c]\n",
    "            counts[c] = defaultdict(int)\n",
    "            for doc in docs:\n",
    "                words = doc.split(\" \")\n",
    "                for word in words:\n",
    "                    counts[c][word] += 1\n",
    "\n",
    "        return counts\n",
    "\n",
    "    def train(self, training_set, training_labels, alpha=1):\n",
    "        # Get number of documents\n",
    "        N_doc = len(training_set)\n",
    "\n",
    "        # Get vocabulary used in training set\n",
    "        self.V = self.compute_vocabulary(training_set)\n",
    "\n",
    "        # Create bigdoc\n",
    "        for x, y in zip(training_set, training_labels):\n",
    "            self.bigdoc[y].append(x)\n",
    "\n",
    "        # Get set of all classes\n",
    "        all_classes = set(training_labels)\n",
    "\n",
    "        # Compute a dictionary with all word counts for each class\n",
    "        self.word_count = self.count_word_in_classes()\n",
    "\n",
    "        # For each class\n",
    "        for c in all_classes:\n",
    "            # Get number of documents for that class\n",
    "            N_c = float(sum(training_labels == c))\n",
    "\n",
    "            # Compute logprior for class\n",
    "            self.logprior[c] = np.log(N_c / N_doc)\n",
    "\n",
    "            # Calculate the sum of counts of words in current class\n",
    "            total_count = 0\n",
    "            for word in self.V:\n",
    "                total_count += self.word_count[c][word]\n",
    "\n",
    "            # For every word, get the count and compute the log-likelihood for this class\n",
    "            for word in self.V:\n",
    "                count = self.word_count[c][word]\n",
    "                self.loglikelihoods[c][word] = np.log((count+ alpha) / (total_count+ alpha))\n",
    "\n",
    "    def predict(self, test_doc):\n",
    "        sums = {\n",
    "            0: 0,\n",
    "            1: 0,\n",
    "        }\n",
    "        for c in self.bigdoc.keys():\n",
    "            sums[c] = self.logprior[c]\n",
    "            words = test_doc.split(\" \")\n",
    "            for word in words:\n",
    "                if word in self.V:\n",
    "                    sums[c] += self.loglikelihoods[c][word]\n",
    "\n",
    "        return sums\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(validation_set,validation_labels,trained_classifier):\n",
    "    correct_predictions = 0\n",
    "    predictions_list = []\n",
    "    prediction = -1\n",
    "    \n",
    "    for dataset,label in zip(validation_set, validation_labels):\n",
    "        #print(label)\n",
    "        probabilities = trained_classifier.predict(dataset)\n",
    "        if probabilities[0] >= probabilities[1]:\n",
    "            prediction = 'negative'\n",
    "        elif  probabilities[0] < probabilities[1]:\n",
    "            prediction = 'positive'\n",
    "        if prediction == label:\n",
    "            correct_predictions += 1\n",
    "            predictions_list.append(\"+\")\n",
    "        else:\n",
    "            predictions_list.append(\"-\")\n",
    "    pp.pprint(\"Predicted correctly {} out of {} ({}%)\".format(correct_predictions,len(validation_labels),round(correct_predictions/len(validation_labels)*100,2)))\n",
    "    return predictions_list, round(correct_predictions/len(validation_labels)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBC = NaiveBayesClassifier()\n",
    "NBC.train(data['TEXT'], data['Sentiment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Context</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The reception through this headset is excellent.</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>GENRE_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Hands down my favorite Italian restaurant!</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>GENRE_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The bathrooms are clean and the place itself i...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>GENRE_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>If you haven't gone here GO NOW!</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>GENRE_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Host staff were, for lack of a better word, BI...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>GENRE_B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               TEXT Sentiment Context  \\\n",
       "0   0   The reception through this headset is excellent.  POSITIVE    NONE   \n",
       "1   1         Hands down my favorite Italian restaurant!  POSITIVE    NONE   \n",
       "2   2  The bathrooms are clean and the place itself i...  POSITIVE    NONE   \n",
       "3   3                   If you haven't gone here GO NOW!  POSITIVE    NONE   \n",
       "4   4  Host staff were, for lack of a better word, BI...  NEGATIVE    NONE   \n",
       "\n",
       "     Genre  \n",
       "0  GENRE_B  \n",
       "1  GENRE_B  \n",
       "2  GENRE_B  \n",
       "3  GENRE_B  \n",
       "4  GENRE_B  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = clean_TEXT(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Context</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>reception headset excellent</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>genre_b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>hands favorite italian restaurant</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>genre_b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>bathrooms clean place decorated</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>genre_b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>haven t gone</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>genre_b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>host staff lack better word bitches</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "      <td>genre_b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                 TEXT Sentiment Context    Genre\n",
       "0   0          reception headset excellent  positive          genre_b\n",
       "1   1    hands favorite italian restaurant  positive          genre_b\n",
       "2   2      bathrooms clean place decorated  positive          genre_b\n",
       "3   3                         haven t gone  positive          genre_b\n",
       "4   4  host staff lack better word bitches  negative          genre_b"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Predicted correctly 1013 out of 2015 (50.27%)'\n",
      "['-', '-', '-', '-', '+', '+', '-', '+', '+', '-', '-', '-', '+', '-', '-', '+', '+', '+', '+', '-', '+', '+', '+', '+', '-', '+', '+', '+', '+', '-', '-', '-', '-', '+', '+', '-', '-', '+', '+', '-', '+', '+', '+', '-', '+', '+', '-', '-', '+', '+', '+', '+', '+', '-', '-', '-', '-', '+', '+', '+', '-', '-', '-', '+', '-', '+', '-', '-', '-', '+', '+', '-', '-', '+', '-', '-', '+', '+', '-', '-', '-', '-', '-', '+', '+', '-', '+', '-', '+', '-', '+', '+', '-', '-', '+', '-', '-', '-', '+', '+', '+', '-', '-', '+', '+', '+', '-', '+', '-', '-', '-', '+', '+', '-', '+', '+', '-', '-', '+', '-', '+', '-', '+', '+', '-', '-', '+', '+', '+', '-', '+', '-', '+', '-', '-', '+', '-', '+', '-', '-', '-', '+', '+', '+', '-', '-', '-', '+', '+', '+', '+', '+', '-', '-', '+', '+', '+', '-', '-', '-', '-', '+', '-', '+', '+', '-', '+', '-', '-', '-', '-', '-', '-', '-', '+', '-', '+', '-', '-', '+', '+', '-', '+', '-', '-', '-', '-', '+', '-', '-', '+', '-', '-', '-', '+', '+', '-', '+', '-', '-', '-', '+', '+', '-', '-', '+', '-', '-', '-', '-', '+', '-', '+', '-', '+', '-', '+', '-', '+', '-', '-', '-', '+', '+', '+', '-', '+', '-', '-', '+', '+', '+', '+', '-', '-', '+', '-', '-', '+', '-', '+', '-', '+', '+', '+', '-', '+', '+', '-', '+', '-', '+', '-', '-', '+', '-', '-', '+', '-', '+', '+', '+', '+', '+', '+', '-', '+', '+', '-', '-', '-', '+', '+', '-', '+', '-', '+', '-', '+', '-', '-', '-', '+', '+', '+', '-', '+', '-', '+', '-', '+', '+', '+', '-', '+', '-', '+', '-', '-', '-', '-', '+', '+', '+', '-', '+', '-', '-', '+', '+', '+', '+', '+', '+', '-', '-', '-', '+', '+', '+', '+', '+', '-', '-', '+', '-', '+', '-', '+', '-', '-', '+', '+', '+', '-', '-', '-', '-', '-', '+', '-', '+', '-', '-', '+', '+', '-', '-', '+', '+', '-', '+', '-', '+', '-', '-', '-', '-', '-', '-', '-', '+', '-', '+', '+', '+', '+', '+', '-', '+', '+', '-', '+', '+', '-', '-', '-', '+', '+', '+', '-', '+', '+', '+', '-', '+', '-', '+', '+', '+', '-', '+', '+', '+', '+', '-', '-', '+', '+', '+', '+', '-', '-', '+', '-', '+', '+', '-', '-', '+', '+', '-', '-', '-', '-', '+', '-', '-', '-', '-', '+', '-', '-', '-', '-', '-', '-', '-', '-', '-', '+', '-', '-', '+', '-', '+', '-', '-', '-', '-', '-', '+', '-', '-', '-', '+', '+', '-', '-', '+', '-', '-', '+', '+', '+', '+', '-', '+', '-', '-', '-', '+', '+', '-', '+', '-', '-', '+', '+', '+', '-', '+', '+', '+', '+', '-', '+', '-', '+', '+', '-', '+', '-', '-', '-', '+', '+', '+', '-', '-', '-', '-', '-', '-', '-', '+', '-', '+', '+', '+', '-', '-', '-', '+', '-', '-', '+', '+', '-', '+', '-', '-', '-', '-', '-', '+', '-', '-', '-', '+', '-', '-', '-', '+', '+', '-', '+', '+', '-', '+', '+', '-', '+', '+', '+', '+', '+', '-', '-', '-', '+', '-', '-', '+', '+', '-', '+', '-', '-', '-', '-', '-', '+', '+', '-', '+', '-', '-', '-', '+', '-', '-', '+', '+', '+', '-', '+', '-', '+', '-', '+', '-', '+', '+', '-', '+', '-', '-', '-', '-', '+', '+', '+', '+', '-', '-', '-', '-', '-', '+', '+', '-', '-', '+', '-', '+', '+', '+', '+', '-', '+', '+', '+', '-', '-', '-', '-', '+', '+', '-', '+', '+', '-', '+', '+', '-', '+', '+', '+', '+', '-', '+', '+', '+', '-', '-', '+', '-', '-', '-', '-', '+', '-', '+', '-', '-', '-', '-', '-', '+', '+', '-', '+', '+', '-', '+', '-', '-', '+', '+', '+', '+', '+', '-', '-', '+', '-', '-', '-', '-', '-', '-', '+', '-', '-', '+', '+', '-', '+', '-', '+', '+', '-', '+', '-', '-', '-', '-', '+', '+', '+', '+', '+', '-', '-', '+', '-', '+', '-', '+', '+', '-', '+', '-', '+', '-', '-', '-', '-', '-', '+', '-', '+', '+', '+', '-', '+', '-', '-', '+', '-', '-', '+', '-', '-', '+', '+', '+', '+', '-', '+', '+', '-', '-', '+', '-', '-', '+', '+', '-', '+', '+', '-', '+', '+', '-', '+', '+', '-', '+', '-', '+', '-', '-', '-', '-', '+', '+', '-', '+', '+', '-', '+', '-', '-', '-', '+', '-', '+', '-', '+', '+', '+', '+', '-', '+', '-', '+', '+', '+', '+', '-', '-', '-', '+', '-', '+', '+', '-', '+', '+', '+', '+', '+', '-', '+', '+', '-', '-', '-', '+', '-', '-', '+', '-', '+', '+', '+', '+', '+', '-', '+', '-', '+', '+', '-', '-', '+', '+', '+', '-', '-', '+', '+', '-', '+', '-', '-', '+', '+', '-', '+', '-', '+', '+', '-', '-', '+', '+', '+', '+', '+', '-', '+', '+', '-', '-', '-', '+', '-', '-', '+', '-', '+', '+', '-', '+', '-', '+', '+', '+', '+', '-', '-', '+', '+', '+', '-', '-', '+', '-', '-', '+', '+', '+', '+', '+', '-', '+', '+', '-', '+', '-', '-', '+', '-', '+', '-', '+', '-', '+', '-', '+', '-', '-', '-', '+', '+', '-', '+', '+', '-', '+', '-', '+', '-', '-', '+', '+', '+', '-', '+', '+', '-', '-', '+', '+', '-', '+', '+', '-', '-', '+', '+', '-', '+', '+', '+', '-', '+', '-', '-', '-', '-', '+', '-', '+', '+', '+', '-', '-', '+', '-', '+', '-', '-', '-', '+', '-', '+', '+', '-', '+', '-', '-', '-', '+', '+', '-', '-', '+', '-', '+', '-', '+', '-', '-', '+', '-', '+', '+', '+', '-', '-', '+', '-', '-', '+', '-', '+', '-', '-', '+', '-', '-', '-', '-', '-', '-', '-', '-', '+', '+', '+', '-', '+', '+', '+', '-', '+', '+', '+', '+', '+', '+', '-', '+', '-', '-', '+', '+', '-', '+', '+', '-', '+', '-', '-', '-', '+', '-', '+', '+', '-', '+', '+', '-', '+', '-', '-', '-', '-', '+', '-', '-', '+', '+', '+', '-', '+', '-', '+', '-', '+', '+', '+', '-', '+', '-', '+', '-', '+', '-', '+', '-', '-', '+', '+', '+', '+', '-', '-', '-', '+', '-', '-', '-', '-', '+', '+', '-', '-', '-', '-', '+', '+', '+', '+', '+', '-', '+', '-', '+', '-', '+', '+', '+', '-', '+', '-', '-', '-', '+', '+', '-', '-', '+', '-', '+', '+', '-', '-', '+', '+', '-', '+', '-', '+', '-', '+', '-', '-', '+', '-', '-', '+', '-', '+', '+', '+', '+', '+', '-', '+', '-', '-', '-', '+', '+', '+', '+', '+', '-', '-', '-', '+', '-', '+', '+', '+', '-', '+', '-', '-', '+', '-', '-', '+', '+', '-', '+', '+', '+', '+', '-', '+', '+', '+', '+', '-', '+', '-', '+', '+', '+', '-', '+', '-', '-', '+', '-', '+', '+', '+', '-', '-', '+', '+', '+', '+', '+', '+', '+', '+', '+', '-', '+', '-', '-', '-', '-', '+', '-', '-', '+', '+', '+', '+', '+', '+', '-', '-', '+', '+', '-', '+', '+', '+', '+', '-', '+', '+', '+', '+', '-', '+', '-', '-', '+', '-', '-', '+', '+', '-', '-', '+', '+', '+', '+', '-', '+', '-', '-', '+', '-', '+', '-', '-', '+', '+', '-', '-', '-', '+', '+', '-', '-', '-', '+', '-', '+', '+', '-', '-', '+', '-', '-', '+', '+', '+', '-', '-', '-', '-', '+', '-', '-', '-', '+', '+', '+', '-', '-', '-', '+', '+', '+', '+', '-', '-', '+', '-', '-', '-', '+', '-', '-', '-', '-', '+', '-', '-', '-', '+', '+', '-', '-', '+', '+', '+', '+', '-', '-', '+', '-', '+', '+', '-', '-', '-', '-', '-', '+', '-', '+', '-', '+', '-', '-', '+', '-', '+', '-', '+', '-', '+', '-', '+', '-', '+', '+', '+', '-', '-', '-', '+', '-', '+', '-', '-', '-', '+', '+', '-', '+', '-', '+', '-', '+', '-', '+', '-', '+', '-', '-', '-', '-', '-', '+', '+', '-', '-', '+', '-', '-', '+', '+', '-', '+', '-', '-', '-', '+', '-', '+', '+', '-', '+', '+', '-', '-', '+', '-', '+', '-', '+', '+', '+', '+', '+', '+', '-', '-', '-', '+', '+', '+', '-', '+', '+', '+', '-', '+', '+', '+', '+', '-', '+', '-', '-', '-', '-', '+', '+', '-', '-', '+', '-', '+', '-', '-', '+', '-', '+', '-', '+', '-', '-', '-', '+', '+', '+', '+', '-', '-', '+', '-', '-', '+', '+', '+', '+', '+', '+', '+', '-', '-', '+', '-', '+', '-', '-', '+', '-', '+', '-', '+', '+', '-', '+', '+', '+', '-', '-', '+', '+', '+', '+', '+', '+', '+', '-', '+', '+', '+', '+', '-', '-', '-', '+', '-', '+', '+', '-', '-', '-', '-', '+', '-', '+', '-', '+', '-', '+', '+', '+', '+', '+', '-', '+', '-', '+', '-', '-', '+', '+', '+', '-', '+', '+', '+', '+', '-', '+', '+', '-', '-', '+', '-', '-', '-', '+', '-', '-', '-', '+', '+', '+', '-', '+', '+', '+', '-', '+', '-', '-', '-', '-', '-', '+', '+', '-', '+', '-', '+', '+', '-', '-', '+', '-', '-', '-', '-', '-', '+', '-', '+', '+', '-', '-', '-', '+', '-', '+', '-', '-', '+', '+', '-', '+', '-', '+', '-', '+', '+', '-', '+', '+', '+', '+', '-', '+', '+', '+', '+', '-', '+', '+', '-', '+', '+', '-', '-', '-', '+', '-', '-', '-', '+', '+', '-', '-', '-', '+', '-', '+', '-', '+', '+', '-', '-', '-', '-', '-', '+', '+', '-', '-', '-', '+', '-', '-', '-', '+', '-', '-', '-', '-', '+', '+', '-', '+', '-', '+', '-', '+', '+', '+', '+', '-', '+', '+', '-', '+', '+', '-', '-', '-', '-', '-', '-', '+', '-', '+', '-', '+', '-', '-', '+', '-', '+', '+', '-', '-', '+', '+', '-', '-', '-', '-', '-', '+', '-', '-', '+', '+', '+', '-', '+', '-', '+', '+', '-', '-', '+', '+', '+', '+', '-', '-', '-', '+', '-', '-', '-', '-', '-', '+', '+', '-', '-', '+', '-', '-', '+', '-', '-', '-', '-', '+', '-', '-', '-', '+', '-', '+', '+', '-', '-', '-', '+', '+', '-', '-', '+', '-', '+', '+', '-', '-', '+', '-', '-', '+', '-', '+', '-', '-', '+', '-', '-', '-', '+', '-', '+', '+', '-', '-', '+', '+', '-', '+', '+', '-', '-', '-', '-', '-', '-', '-', '+', '-', '-', '+', '-', '+', '+', '-', '+', '+', '+', '+', '+', '+', '+', '-', '+', '-', '-', '+', '+', '+', '-', '+', '+', '-', '+', '-', '+', '-', '-', '-', '+', '-', '+', '+', '+', '+', '+', '-', '+', '-', '-', '-', '-', '+', '-', '+', '-', '+', '-', '+', '-', '+', '-', '+', '+', '-', '+', '+', '+', '-', '-', '-', '+', '+', '+', '-', '+', '+', '-', '-', '+', '-', '-', '-', '+', '-', '-', '+', '-', '-', '-', '-', '+', '-', '-', '-', '-', '+', '-', '-', '+', '+', '+', '+', '-', '+', '+', '-', '-', '+', '-', '+', '+', '-', '-', '-', '-', '-', '+', '+', '+', '+', '+', '+', '+', '-', '+', '+', '+', '-', '-', '+', '+', '-', '-', '+', '+', '+', '+', '+', '-', '+', '-', '+', '-', '-', '-', '+', '-', '+', '+', '-', '-', '+', '+', '-', '-', '-', '+', '-', '+', '-', '+', '-', '-', '-', '-', '+', '-', '-', '-', '-', '+', '-', '-', '+', '+', '-', '+', '-', '+', '+', '-', '+', '+', '+', '-', '+', '-', '-', '-', '+', '+', '-', '-', '+', '-', '+', '+', '-', '+', '+', '+', '+', '-', '+', '-', '+', '-', '+', '+', '-', '+', '+', '-', '-', '+', '-', '+', '-', '+', '+', '-', '-', '-', '+', '+', '-', '+', '+', '+', '+', '+', '-', '+', '-', '-', '-', '+', '+', '-', '+', '+', '+', '+', '-', '-', '+', '+', '+', '-', '+', '+', '-', '+', '-', '-', '+', '+', '+', '-', '-', '-', '-', '+', '+', '-', '-', '+', '-', '+', '+', '+'] 50\n"
     ]
    }
   ],
   "source": [
    "result, acc = evaluate_predictions(test_df['TEXT'], test_df['Sentiment'],NBC)\n",
    "print(result, acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
